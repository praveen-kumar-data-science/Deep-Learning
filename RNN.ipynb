{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('D:\\\\DL Colab Changes\\\\DL Colab Changes\\\\Recurrent_Neural_Networks 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values  #Single column with opening stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a datastructure with 60 timestamps and one output\n",
    "X_train =[]\n",
    "y_train =[]\n",
    "for i in range(60, training_set_scaled.shape[0]):\n",
    "    X_train.append(training_set_scaled[i-60:i,0 ])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "    \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1198, 60), (1198,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping to 3D (RNN asks this)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 3623s 3s/step - loss: 0.0446\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 4013s 3s/step - loss: 0.0069\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 3595s 3s/step - loss: 0.0062\n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 3596s 3s/step - loss: 0.0063\n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 3595s 3s/step - loss: 0.0048\n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 3607s 3s/step - loss: 0.0051\n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 3721s 3s/step - loss: 0.0048\n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 4227s 4s/step - loss: 0.0046\n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 3587s 3s/step - loss: 0.0049\n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 3594s 3s/step - loss: 0.0041\n",
      "Epoch 11/100\n",
      " 704/1198 [================>.............] - ETA: 24:36 - loss: 0.0040"
     ]
    }
   ],
   "source": [
    "#Build RNN\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#Inialize RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "#Adding first layer and some droupout regulaization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "#Adding the second layer and some droupout regulaization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "#Adding the third layer and some droupout regulaization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "#Adding the fourth layer and some droupout regulaization\n",
    "regressor.add(LSTM(units = 50))  #Default return_sequences = False for the last LSTM layer\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "#Adding the output layer (fully connected network)\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "#Compiling RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "#Fitting RNN to training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "\n",
    "#Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "#Getting the predicted stock price\n",
    "dataset_total = pd.concat(dataset_train['Open'], dataset_test['Open'], axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60 :].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,80):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing results\n",
    "plt.plot(real_stock_price, color = 'red', label= \"Real google stock price\")\n",
    "plt.plot(predicted_stock_price, color = 'blue', label='Predicted Google Stock Price')\n",
    "plt.title('Google stock price prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the RNN\n",
    "Hi guys,\n",
    "\n",
    "as seen in the practical lectures, the RNN we built was a regressor. Indeed, we were dealing with Regression because we were trying to predict a continuous outcome (the Google Stock Price). For Regression, the way to evaluate the model performance is with a metric called RMSE (Root Mean Squared Error). It is calculated as the root of the mean of the squared differences between the predictions and the real values.\n",
    "\n",
    "However for our specific Stock Price Prediction problem, evaluating the model with the RMSE does not make much sense, since we are more interested in the directions taken by our predictions, rather than the closeness of their values to the real stock price. We want to check if our predictions follow the same directions as the real stock price and we don’t really care whether our predictions are close the real stock price. The predictions could indeed be close but often taking the opposite direction from the real stock price.\n",
    "\n",
    "Nevertheless if you are interested in the code that computes the RMSE for our Stock Price Prediction problem, please find it just below:\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
    "Then consider dividing this RMSE by the range of the Google Stock Price values of January 2017 (that is around 800) to get a relative error, as opposed to an absolute error. It is more relevant since for example if you get an RMSE of 50, then this error would be very big if the stock price values\n",
    "ranged around 100, but it would be very small if the stock price values ranged around 10000.\n",
    "\n",
    "Enjoy Deep Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the RNN\n",
    "Hi guys,\n",
    "\n",
    "here are different ways to improve the RNN model:\n",
    "\n",
    "Getting more training data: we trained our model on the past 5 years of the Google Stock Price but it would be even better to train it on the past 10 years.\n",
    "Increasing the number of timesteps: the model remembered the stock prices from the 60 previous financial days to predict the stock price of the next day. That’s because we chose a number of 60 timesteps (3 months). You could try to increase the number of timesteps, by choosing for example 120 timesteps (6 months).\n",
    "Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.\n",
    "Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.\n",
    "Adding more neurones in the LSTM layers: we highlighted the fact that we needed a high number of neurones in the LSTM layers to respond better to the complexity of the problem and we chose to include 50 neurones in each of our 4 LSTM layers. You could try an architecture with even more neurones in each of the 4 (or more) LSTM layers.\n",
    "Enjoy Deep Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the RNN\n",
    "Hi guys,\n",
    "\n",
    "you can do some Parameter Tuning on the RNN model we implemented.\n",
    "\n",
    "Remember, this time we are dealing with a Regression problem because we predict a continuous outcome (the Google Stock Price).\n",
    "\n",
    "Parameter Tuning for Regression is the same as Parameter Tuning for Classification which you learned in Part 1 - Artificial Neural Networks, the only difference is that you have to replace:\n",
    "\n",
    "scoring = 'accuracy'  \n",
    "\n",
    "by:\n",
    "\n",
    "scoring = 'neg_mean_squared_error' \n",
    "\n",
    "in the GridSearchCV class parameters.\n",
    "\n",
    "Enjoy Deep Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
